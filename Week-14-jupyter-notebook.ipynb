{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b02ee8f",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647d6e7",
   "metadata": {},
   "source": [
    "For Week 14, include the concept of Gaussian mixture models. Complete your Jupyter Notebook homework by 11:59pm ET on Saturday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54049339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import feature engineering and selection libraries\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# data preprocesing\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# sampling methods\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ebdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df_or_series, cat_cols: list = None, one_hot: bool = False):\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in a DataFrame or a single pandas Series.\n",
    "\n",
    "    Args:\n",
    "        df_or_series: DataFrame or Series to encode.\n",
    "        cat_cols: List of columns to encode (only used if input is DataFrame).\n",
    "        one_hot: If True, use one-hot encoding for DataFrame input.\n",
    "\n",
    "    Returns:\n",
    "        If input is DataFrame: (encoded DataFrame, mappings dict or list of new columns)\n",
    "        If input is Series: (encoded Series, mapping dict)\n",
    "    \"\"\"\n",
    "    if isinstance(df_or_series, pd.Series):\n",
    "        uniques = df_or_series.dropna().unique().tolist()\n",
    "        mapping = {cat: code for code, cat in enumerate(uniques)}\n",
    "        encoded = df_or_series.map(mapping).astype(\"int64\")\n",
    "        return encoded\n",
    "    \n",
    "    elif isinstance(df_or_series, pd.DataFrame):\n",
    "        if one_hot:\n",
    "            if cat_cols is None:\n",
    "                cat_cols = df_or_series.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "            df_encoded = pd.get_dummies(df_or_series, columns=cat_cols, drop_first=True)\n",
    "            return df_encoded\n",
    "        else:\n",
    "            df_encoded = df_or_series.copy()\n",
    "            mappings = {}\n",
    "            if cat_cols is None:\n",
    "                cat_cols = df_encoded.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "            for col in cat_cols:\n",
    "                uniques = df_encoded[col].dropna().unique().tolist()\n",
    "                mapping = {cat: code for code, cat in enumerate(uniques)}\n",
    "                mappings[col] = mapping\n",
    "                df_encoded[col] = df_encoded[col].map(mapping).astype(\"int64\")\n",
    "            return df_encoded\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Input must be a pandas DataFrame or Series.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e43878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(file_path: str, target_col: str = None, one_hot: bool = False, test_size: float = 0.2, random_state: int = 0, scaling: str = None, sampling: str = None):\n",
    "    \"\"\"\n",
    "    Loads data, encodes categorical features, splits into train/test, and scales features.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to CSV file.\n",
    "        target_col: Name of target column. If None, uses last column.\n",
    "        test_size: Fraction for test split.\n",
    "        random_state: Random seed.\n",
    "        scaling: 'norm' (MinMax), 'reg' (Standard), or None.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, df, mappings\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Select target\n",
    "    if target_col is None:\n",
    "        target_col = df.columns[-1]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Encode Categorical Features\n",
    "    if one_hot is True:\n",
    "        X_encoded = encoding(X, one_hot=True)\n",
    "        if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "            y_encoded = encoding(y)\n",
    "        else:\n",
    "            y_encoded = y\n",
    "    else:\n",
    "        X_encoded = encoding(X)\n",
    "        if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "            y_encoded = encoding(y)\n",
    "        else:\n",
    "            y_encoded = y\n",
    "            \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded, y_encoded, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "     # Optional sampling (TRAIN ONLY)\n",
    "    if sampling is not None:\n",
    "        sampler = None\n",
    "        if sampling.lower() == 'smote':\n",
    "            sampler = SMOTE(random_state=random_state, sampling_strategy='auto')\n",
    "        else:\n",
    "            raise ValueError(\"sampling must be one of: None, 'smote'.\")\n",
    "\n",
    "        X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Rebuild DataFrame / Series\n",
    "        X_train = pd.DataFrame(X_train_res, columns=X_train.columns)\n",
    "        y_train = pd.Series(y_train_res, name=target_col)\n",
    "\n",
    "    # Reset indices\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    # Scaling\n",
    "    if scaling == 'reg':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling == 'norm':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    if scaler is not None:\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
